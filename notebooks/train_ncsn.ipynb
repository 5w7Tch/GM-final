{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCSN Training on CIFAR-10\n",
    "**Noise Conditional Score Network**\n",
    "\n",
    "This notebook trains NCSN for unconditional image generation on CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/5w7Tch/GM-final.git\n",
    "%cd GM-final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install wandb tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from our repo\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.models import NCSN, get_sigmas\n",
    "from src.losses import anneal_dsm_loss\n",
    "from src.sampling import generate_samples\n",
    "from src.data import get_dataloader, denormalize\n",
    "from src.utils import EMA, show_samples, save_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wandb (optional)\n",
    "USE_WANDB = True\n",
    "\n",
    "if USE_WANDB:\n",
    "    import wandb\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Model\n",
    "    'num_features': 128,\n",
    "    'num_classes': 10,\n",
    "    \n",
    "    # Noise schedule\n",
    "    'sigma_begin': 1.0,\n",
    "    'sigma_end': 0.01,\n",
    "    \n",
    "    # Training\n",
    "    'epochs': 200,\n",
    "    'batch_size': 128,\n",
    "    'lr': 1e-4,\n",
    "    'ema_decay': 0.999,\n",
    "    \n",
    "    # Sampling\n",
    "    'n_steps_each': 100,\n",
    "    'step_lr': 2e-5,\n",
    "    \n",
    "    # Logging\n",
    "    'sample_every': 10,\n",
    "    'save_every': 25,\n",
    "    \n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "torch.manual_seed(config['seed'])\n",
    "\n",
    "# Directories\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "os.makedirs('samples', exist_ok=True)\n",
    "\n",
    "# Data\n",
    "train_loader = get_dataloader(batch_size=config['batch_size'], train=True)\n",
    "print(f\"Training batches: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = NCSN(\n",
    "    num_classes=config['num_classes'],\n",
    "    num_features=config['num_features']\n",
    ").to(device)\n",
    "\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Sigmas\n",
    "sigmas = get_sigmas(\n",
    "    config['sigma_begin'],\n",
    "    config['sigma_end'],\n",
    "    config['num_classes']\n",
    ").to(device)\n",
    "\n",
    "print(f\"Sigmas: {sigmas.cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=config['epochs'] * len(train_loader)\n",
    ")\n",
    "\n",
    "# EMA\n",
    "ema = EMA(model, decay=config['ema_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wandb\n",
    "if USE_WANDB:\n",
    "    wandb.init(\n",
    "        project='ML2-NCSN',\n",
    "        config=config,\n",
    "        name=f'ncsn_{datetime.now().strftime(\"%m%d_%H%M\")}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['epochs']}\")\n",
    "    \n",
    "    for images, _ in pbar:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        loss = anneal_dsm_loss(model, images, sigmas)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        ema.update()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        global_step += 1\n",
    "        \n",
    "        pbar.set_postfix(loss=f'{loss.item():.4f}')\n",
    "        \n",
    "        if USE_WANDB and global_step % 50 == 0:\n",
    "            wandb.log({'loss': loss.item(), 'lr': scheduler.get_last_lr()[0]}, step=global_step)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} - Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    # Generate samples\n",
    "    if (epoch + 1) % config['sample_every'] == 0:\n",
    "        ema.apply_shadow()\n",
    "        model.eval()\n",
    "        \n",
    "        samples = generate_samples(\n",
    "            model, sigmas, n_samples=64,\n",
    "            n_steps_each=config['n_steps_each'],\n",
    "            step_lr=config['step_lr'],\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        save_samples(samples, f'samples/epoch_{epoch+1:04d}.png')\n",
    "        show_samples(samples, title=f'Epoch {epoch+1}')\n",
    "        \n",
    "        if USE_WANDB:\n",
    "            wandb.log({'samples': wandb.Image(f'samples/epoch_{epoch+1:04d}.png')}, step=global_step)\n",
    "        \n",
    "        ema.restore()\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if (epoch + 1) % config['save_every'] == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'ema': ema.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'sigmas': sigmas.cpu(),\n",
    "            'config': config\n",
    "        }, f'checkpoints/epoch_{epoch+1:04d}.pt')\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "if USE_WANDB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply EMA weights\n",
    "ema.apply_shadow()\n",
    "model.eval()\n",
    "\n",
    "# Generate with more steps\n",
    "final_samples = generate_samples(\n",
    "    model, sigmas, n_samples=64,\n",
    "    n_steps_each=200,\n",
    "    step_lr=2e-5,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "show_samples(final_samples, title='Final Samples')\n",
    "save_samples(final_samples, 'samples/final.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "torch.save({\n",
    "    'model': model.state_dict(),\n",
    "    'ema': ema.state_dict(),\n",
    "    'sigmas': sigmas.cpu(),\n",
    "    'config': config\n",
    "}, 'checkpoints/final.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r results.zip checkpoints/ samples/\n",
    "\n",
    "from google.colab import files\n",
    "files.download('results.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
